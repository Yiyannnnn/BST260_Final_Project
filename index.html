<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Yiyan Zhang" />


<title>Machine Learning Application on Human Gut Microbiome Data</title>

<script src="site_libs/header-attrs-2.18/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/darkly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Yiyan Zhang Final Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Tables.html">Tables &amp; Figures</a>
</li>
<li>
  <a href="Code_Appendix.html">Code</a>
</li>
<li>
  <a href="index.html">Report</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Machine Learning Application on Human Gut
Microbiome Data</h1>
<h4 class="author">Yiyan Zhang</h4>

</div>


<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>The human body (especially the gastrointestinal tract) harbors a
diverse of microorganisms that includes bacteria, protozoa, archaea,
viruses, and fungi (Huseyin et al., 2017). The gut microbiota has
notable influence on the host health and the dysbiosis of gut microbiota
has been associated with many diseases (Thursby &amp; Juge, 2017). Thus,
in this project, I would take the advantage of the metagenomic
information from human gut to make the classification between healthy
and disease samples with several popular machine learning models.</p>
<p>In this study, I leveraged gut microbiome samples from a publicly
available large-scale metagenomic database — curatedMetagenomicData
(CMD; version 3.6.0) which contains uniformly processed human microbiome
taxonomic abundances data and phenotypic data (Pasolli et al., 2017). I
selected samples based on two criteria: the host age is between 18 and
65; no antibiotic use. Samples include healthy individuals, as well
individuals with one of the following diseases: Inflammatory Bowel
Disease (IBD), Colorectal cancer (CRC), Impaired Glucose Tolerance
(IGT), and Type 2 Diabetes (T2D). The final dataset includes 2,815
healthy samples, 768 IBD samples, 368 CRC samples, 199 IGT samples, and
164 T2D samples. I also filtered out those species whose prevalence were
lower than 0.1, resulting in 194 species. Here, we performed explanatory
data analysis to get the overall view of the structure of our data. For
age, we have a relatively elder cohort for CRC and IGT, which are around
55 years old. For gender, the overall proportion are relatively close,
but for three of our disease cohort (CRC IGT and T2D) is dominant by
male. Luckily, we do not have much missingness in our data. Also, I
explored alpha diversity of each disease status for microbiome
composition as a regular microbiome data explanatory approach. It is
measuring the diversity of microbiome species within an individual
sample. The oldest and the simplest concept of species diversity: the
total number of species present in a sample or community, which is the
observed here. Chao 1 index is based upon the number of rare species
found in a sample. Shannon diversity index is one of the most popular
measures of species diversity. It considers the differences in
proportion or abundance of each species. Simpson’s Diversity Index is a
measure of diversity which considers the number of species present, as
well as the relative abundance of each species. From the violin plots
for different measurements, we do not observed much difference among
groups.</p>
<p>In this analysis, I will apply PCA between healthy and each disease
group first, as the number of features is relatively large for
microbiome datasets. This step can help to get sense whether disease
samples are easy to differentiate from healthy samples based on
microbiome composition. However, this step will loss the
interpretability of the model, and one of the goals of metagenomic study
is to find the taxonomy marker associated with different disease. Thus,
I will use abundance table as the input for classification. I will
employ the state-of-the-art machine learning methods which have been
shown as powerful tools to do the classification in previous study (Wang
&amp; Liu, 2020), including logistic regression model with further
feature selection using LASSO (Logit-Lasso) and Random Forest (RF). For
each method, I will use k-fold cross-validation to select the best model
and use k-fold cross-validation in higher structure to estimate the
model performance. In order to better evaluate the model performance, I
used accuracy, F1 score, and area under precision and recall curve
(AUPRC). Considering we have much more heathy samples than the disease
samples, I figured out F1 score and AUPRC might works better than
accuracy under the imbalance data setting. I will also discuss this
issue in detail at the results part.</p>
</div>
<div id="results" class="section level3">
<h3>Results</h3>
<p>PCA is a useful tool for analyzing and understanding the complexity
of the microbiome, and it can help researchers identify important
patterns and relationships that may not be immediately apparent from the
raw data. First, I generated PCA plots for each disease samples
comparing with healthy samples. From the plots for four diseases, we can
only observe some differentiation in IBD at bottom left part. PCA plots
for other diseases are Thus, we might expect the classification for most
disease would be relatively hard to achieve, but IBD might have better
performance among all diseases.</p>
<p>Then, I trained logistic regression model with variable selection
using LASSO with 10-fold cross validation as we have the binary outcome
of healthy or disease and a huge amount of taxonomy abundance features.
I also performed 10-fold cross-validation to evaluate model performance.
In the performance table, we can see that the average accuracy for IBD,
CRC, IGT, and T2D are 0.918, 0.916, 0.964, and 0.946 respectively; the
average F1 score are 0.806, 0.539, 0.724, and 0.347 respectively; and
the average AUPRC are 0.856, 0.577, 0.572, and 0.577 respectively. I
also trained random forest with 10-fold cross-validation to select best
number of variables randomly sampled as candidates at each split.
Similarly, I also used 10-fold cross-validation to evaluate the model
performance. In the performance table, we can see that the average
accuracy for IBD, CRC, IGT, and T2D are 0.954, 0.930, 0.984, and 0.951
respectively; the average F1 score are 0.883, 0.734, 0.855, and 0.319
respectively; and the average AUPRC are 0.975, 0.734, 0.975, and 0.523
respectively. All model results are presented in Table 2. Generally, as
we expected, the classification of IBD is easier, but the performance
for IGT classification is also relative good. Also, for T2D, we can see
the performance are poor which might be caused by limited sample
size.</p>
<p>In addition, I investigated the important species to classify the
disease status. Figure 3 shows the Venn diagram of species included for
each disease logistic regression model. Noticeably, IGT included 116
species which is the largest model. In total, there are 8 species
included in all models. For random forest model, I plotted variable
importance plot for models of each disease as well (see Figure 4). We
found Gemmiger formicilis, Streptococcus oralis, Parabacteroides
johnsonii, and Enterocloster bolteae are the model’s most important
biomarker for IBD, CRC, IGT, and T2D respectively.</p>
<p>In order to conduct systematic comparison of model, I plotted boxplot
of all model performance based on accuracy, F1 score, and AUPRC in
Figure 5-7. Based on these results, it seems that the random forest
model performs well across all four medical conditions, with generally
higher accuracy, F1 scores, and AUPRC values compared to the logistic
regression and LASSO models. However, it is worth noting that the
performance of the models may vary depending on the specific
characteristics of the data and the specific task at hand, and it is
always important to consider multiple evaluation metrics to get a
comprehensive understanding of the model’s performance. The results are
shown in terms of four evaluation metrics: accuracy, F1 score, and area
under the precision-recall curve (AUPRC). Accuracy is a commonly used
evaluation metric in machine learning, but it may not always be the best
choice, especially when the classes in the data are imbalanced like in
our data. In such cases, using accuracy as the sole evaluation metric
can be misleading because it does not take into account the relative
sizes of the two classes. For example, if the data consists of 99%
negative cases and 1% positive cases, a model that always predicts
negative could achieve high accuracy simply by guessing the most common
class. However, this model would not be very useful in practice because
it would not be able to detect the positive cases.</p>
<p>In this case, using other evaluation metrics that are more sensitive
to class imbalance can be more informative. One such metric is the F1
score, which is a balance of precision and recall. Precision is the
proportion of true positive predictions made by the model out of all
positive predictions, and recall is the proportion of true positive
predictions made by the model out of all actual positive cases. The F1
score is the harmonic mean of precision and recall, and it is a good
metric to use when you want to balance the false positive and false
negative rates. Another metric that can be useful when the classes are
imbalanced is the area under the precision-recall curve (AUPRC). The
AUPRC is a measure of the model’s ability to discriminate between
positive and negative cases, and it is useful when the classes are
imbalanced because it is more sensitive to changes in the recall rate
than the precision rate.</p>
<p>Overall, it is important to consider multiple evaluation metrics and
choose the ones that are most appropriate for the specific task and the
characteristics of the data. In cases where the classes are imbalanced,
using metrics such as the F1 score and the AUPRC can provide a more
comprehensive understanding of the model’s performance compared to using
accuracy alone.</p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>In conclusion, the machine learning models applied in this study were
able to effectively classify samples from healthy individuals and those
with various diseases using data from the human gut microbiome. PCA was
first used to get a sense of whether disease samples could be easily
differentiated from healthy samples based on microbiome composition. The
Logit-Lasso and RF classification methods were then applied, with k-fold
cross-validation used to select the best model and estimate performance.
The Logit-Lasso model performed adequately good overall, with high
accuracy, F1 score, and AUPRC in all disease groups. The Random Forest
model showed stronger performance and may be more suitable for cases
where interpretability of the model is important.</p>
<p>These results highlight the potential of machine learning techniques
in analyzing and understanding the complex relationships between the gut
microbiome and human health. However, this study did not cooperate much
microbiome data specific features in our analysis, like sparsity,
compositionality, and small n large p problem. Further studies with
larger and more diverse datasets may be necessary to fully explore the
potential of these methods in the field of gut microbiome research.
There is also more machine learning framework are available. Also, out
study are limited at two-class classification. More pivotal studies that
worked on multi-class classification give me further directions on the
project (Su et al., 2022).</p>
</div>
<div id="reference" class="section level3">
<h3>Reference</h3>
<p>Huseyin, C. E., O’Toole, P. W., Cotter, P. D., &amp; Scanlan, P. D.
(2017). Forgotten fungi—The gut mycobiome in human health and disease.
FEMS Microbiology Reviews, 41(4), 479–511. <a
href="https://doi.org/10.1093/femsre/fuw047"
class="uri">https://doi.org/10.1093/femsre/fuw047</a></p>
<p>Pasolli, E., Schiffer, L., Manghi, P., Renson, A., Obenchain, V.,
Truong, D. T., Beghini, F., Malik, F., Ramos, M., Dowd, J. B.,
Huttenhower, C., Morgan, M., Segata, N., &amp; Waldron, L. (2017).
Accessible, curated metagenomic data through ExperimentHub. Nature
Methods, 14(11), Article 11. <a
href="https://doi.org/10.1038/nmeth.4468"
class="uri">https://doi.org/10.1038/nmeth.4468</a></p>
<p>Thursby, E., &amp; Juge, N. (2017). Introduction to the human gut
microbiota. Biochemical Journal, 474(11), 1823–1836. <a
href="https://doi.org/10.1042/BCJ20160510"
class="uri">https://doi.org/10.1042/BCJ20160510</a></p>
<p>Wang, X., &amp; Liu, Y. (2020). Comparative study of classifiers for
human microbiome data. Medicine in Microecology, 4, 100013. <a
href="https://doi.org/10.1016/j.medmic.2020.100013"
class="uri">https://doi.org/10.1016/j.medmic.2020.100013</a></p>
<p>Su, Q., Liu, Q., Lau, R. I., Zhang, J., Xu, Z., Yeoh, Y. K., Leung,
T. W. H., Tang, W., Zhang, L., Liang, J. Q. Y., Yau, Y. K., Zheng, J.,
Liu, C., Zhang, M., Cheung, C. P., Ching, J. Y. L., Tun, H. M., Yu, J.,
Chan, F. K. L., &amp; Ng, S. C. (2022). Faecal microbiome-based machine
learning for multi-class disease diagnosis. Nature Communications,
13(1), 6818-6818. <a href="https://doi.org/10.1038/s41467-022-34405-3"
class="uri">https://doi.org/10.1038/s41467-022-34405-3</a></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
